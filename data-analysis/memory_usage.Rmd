# An Empirical Study on the Memory Usage and Performance of Python code using Python Memory Efficiency Guidelines -- NNDEV

## Setup (Installations)
```{r, results='hide', message=FALSE}
install.packages(c("tidyverse", "ggplot2", "bestNormalize", "ARTool", "lmerTest", "xtable"))
library(tidyverse)
library(ggplot2)
library(bestNormalize)
library(ARTool)
library(lmerTest)
library(xtable)
```

## 1. Data Loading and Inspection

```{r}
setwd("/Users/nhimai/Documents/MCs/Green-Lab/green-lab-project-nndev/data-analysis")
dat_data <- read.csv("../benchmarks/experiments/run_table.csv") %>%
  select(guideline, code, treatment, run_number, memory_usage, execution_time, cpu_usage, memory_usage) %>%
  mutate(
    guideline = factor(guideline),
    code = factor(code),
    treatment = factor(treatment),
    run_number = factor(run_number)
  )

dat_data <- dat_data %>%
  filter(!is.na(memory_usage) & !is.na(guideline) & !is.na(treatment))

glimpse(dat_data)
summary(dat_data)
head(dat_data)
```

## 2. Visual Exploration via Plotting

### 2.1. Histogram of memory_usage

### 2.1.1. Overall

```{r}
p <- ggplot(dat_data, aes(x = memory_usage)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Histogram of Memory Usage",
    x = "Memory Usage",
    y = "Frequency"
  )

ggsave("figures/memory_usage_histogram.png", plot = p, width = 8, height = 6, dpi = 300)
```

#### 2.1.2. Split by treatment
```{r}
p <- ggplot(dat_data, aes(x = memory_usage, fill = treatment)) +
  geom_histogram(bins = 30, alpha = 0.6, position = "identity") +
  facet_wrap(~ guideline, scales = "free_x") +
  theme_minimal() +
  labs(
    title = "Memory Usage Distribution by Treatment",
    x = "Memory Usage",
    y = "Frequency",
    fill = "Treatment"
  )


ggsave("figures/memory_usage_histogram_by_treatment.png", plot = p, width = 8, height = 6, dpi = 300)
```

### 2.2. Box plot of memory_usage grouped by treatment and guideline
```{r}
p <- ggplot(dat_data, aes(x = treatment, y = memory_usage, fill=guideline)) +
  geom_boxplot(alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Memory Usage by Treatment",
    x = "Treatment",
    y = "Memory Usage",
    fill = "Guideline"
  )


ggsave("figures/memory_usage_box_plot.png", plot = p, width = 8, height = 6, dpi = 300)
```

#### 2.3. Scatterplots of memory_usage across trials: define "experiment" as guideline + treatment
```{r}
dat_data <- dat_data %>%
  mutate(
    experiment = interaction(guideline, treatment),
    run_number = factor(run_number, levels = paste0("r", 1:20), ordered = TRUE)
    )

p <- ggplot(dat_data, aes(x = run_number, y = memory_usage, color = experiment)) +
  geom_point(alpha = 0.8, size = 2) +
  theme_minimal() +
  labs(
    title = "Memory Usage Across Runs",
    x = "Run Number",
    y = "Memory Usage",
    color = "Experiment"
  )

ggsave("figures/memory_usage_scatterplot.png", plot = p, width = 8, height = 6, dpi = 300)
```


## 3. Data Normality and Normalization

### 3.1. Shapiro-Wilk test
```{r}
# Run Shapiro-Wilk for each group
normality_results <- dat_data %>%
  group_by(guideline, treatment) %>%
  summarise(
    shapiro_p = shapiro.test(memory_usage)$p.value,
    .groups = "drop"
  )

normality_results
```

- Interpretation: if p < 0.05, reject normality (data is not normal).

### 3.2. Normalize the memory_usage column
```{r}
bn <- bestNormalize(dat_data$memory_usage)
dat_data$norm_memory_usage <- bn$x.t
```

### 3.3. Visualization of normalized data and repeat normality tests

#### 3.3.1. Histogram of normalized data
```{r}
ggplot(dat_data, aes(x = norm_memory_usage)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black") +
  theme_minimal() +
  labs(
    title = "Histogram of Normalized Memory Usage",
    x = "Normalized Memory Usage",
    y = "Frequency"
  )
```

#### 3.3.2. Shapiro-Wilk again for normalized values
```{r}
normality_results_norm <- dat_data %>%
  group_by(guideline, treatment) %>%
  summarise(
    shapiro_p = shapiro.test(norm_memory_usage)$p.value,
    .groups = "drop"
  )

normality_results_norm
```
- If most *shapiro_p* values after normalization are greater than 0.05, then distributions can be considered normal, and parametric tests (t-test) are justified.
- If many are still below 0.05, non-parametric test (Wilcoxon) will be the case.

## 4. Non-parametric test

### 4.1. Wilcoxonâ€™s test

#### Compare entire set
```{r, results='hide', message=FALSE}
all_no_guideline_j = dat_data[dat_data$treatment == 'no_guideline',]$memory_usage
all_guideline_j = dat_data[dat_data$treatment == 'guideline',]$memory_usage
wilcox.test(all_no_guideline_j, all_guideline_j)

# g1_no_guideline = dat_data[dat_data$treatment == 'no_guideline' & dat_data$guideline == 'G1',]$memory_usage
# g1_guideline = dat_data[dat_data$treatment == 'guideline' & dat_data$guideline == 'G1',]$memory_usage
# wilcox.test(g1_no_guideline, g1_guideline)
```

#### Compare different treatments in terms of guidelines
```{r}
guidelines <- unique(dat_data$guideline)
wilcox_results <- map_dfr(guidelines, function(g) {
  subset_data <- dat_data %>% filter(guideline == g)
  
  no_guideline_j <- subset_data %>% filter(treatment == "no_guideline") %>% pull(memory_usage)
  guideline_j     <- subset_data %>% filter(treatment == "guideline") %>% pull(memory_usage)
  
  test_result <- wilcox.test(no_guideline_j, guideline_j)
  
  tibble(
    guideline = g,
    p_value = test_result$p.value,
    statistic = test_result$statistic,
    method = test_result$method
  )
})

print(wilcox_results)
```

### 4.2. ART (Aligned Rank Transform) model
```{r}
art_model <- art(memory_usage ~ guideline * treatment + (1|run_number), data = dat_data)
summary(art_model)
```

### 4.3. LMER model
```{r, results='hide', message=FALSE}
lmer_model = lmer(memory_usage ~ guideline * treatment + (1|run_number), data = dat_data)
summary(lmer_model)
anova(lmer_model)
```

### 4.4. Check residuals for normality
```{r}
res_model <- resid(model)
qqnorm(res_model)
qqline(res_model, col = "red", lwd = 2)
shapiro.test(res_model)
```

## 5. Summary plot

## 5.1. Boxplot of memory_usage by code, faceted by guideline
```{r}
ggplot(dat_data, aes(x = as.factor(code), y = memory_usage)) +
  geom_boxplot(fill = "skyblue", color = "darkblue") +
  facet_wrap(~ guideline, scales = "free") +
  labs(x = "Code", y = "Memory Usage", title = "Memory Usage Distribution by Code") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## 5.3. Scatter plot of memory_usage over run_number, colored by guideline
```{r}
ggplot(dat_data, aes(x = run_number, y = memory_usage, color = guideline)) +
  geom_point(alpha = 0.7, size = 2) +
  labs(x = "Run Number", y = "Memory Usage", title = "Memory Usage over Run Number") +
  theme_minimal() +
  theme(legend.position = "right")
```

## 5.4. Scatter plot of memory_usage vs execution_time, faceted by guideline, with trend lines
```{r}
ggplot(dat_data, aes(x = execution_time, y = memory_usage)) +
  geom_point(aes(color = guideline), alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  facet_wrap(~ guideline, ncol = 2, scales = "free") +
  labs(x = "Execution Time", y = "Memory Usage", title = "Memory Usage vs Execution Time by Guideline") +
  theme_minimal()
```